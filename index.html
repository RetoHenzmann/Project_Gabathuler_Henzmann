<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Reto Henzmann and Gabathuler Oswald">

<title>GPS-based traffic mode detection: Implementation and validation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">GPS-based traffic mode detection: Implementation and validation</h1>
<p class="subtitle lead">Analyzing Transport Modes through GPS-Data and Road Maps: A Comparative Study with Posmo</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Reto Henzmann and Gabathuler Oswald </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>This study investigates travel mode detection using GPS data, a critical aspect of transportation planning and optimization. Traditional methods like household surveys are often inaccurate and costly. With the advent of smartphones, extensive GPS data collection has become feasible, yet extracting travel modes from this data remains challenging. We implemented a rule-based approach in R, using data from the POSMO app and the swissTLM3D dataset. Our method, incorporating geographical context, aimed to classify travel modes such as walking, biking, car, bus, and train. Despite initial classification errors, manual corrections improved accuracy. The validation of our method showed a correct detection rate of 88.2%, with the most significant improvement seen in the classification of train trajectories. This study underscores the potential of geographic context to improve the accuracy of travel mode detection from GPS data.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Travel mode detection, particularly using GPS data, is crucial for effective transportation planning and optimization. It lays the groundwork for strategies aimed at reducing traffic congestion and pollution (Nitsche et al., 2014). Traditionally, travel information was collected through household surveys and telephone interviews (Stopher and Greaves, 2007; Gadziński, 2018; Dabiri et al., 2020). However, these methods are often inaccurate, time-consuming, and expensive (Stopher and Greaves, 2007; Li et al., 2019; Gadziński, 2018). The advent of smartphones with GPS capabilities has revolutionized data collection, allowing for extensive and detailed gathering of spatial and temporal data (Wu et al., 2016). While GPS data provides comprehensive geometric and temporal information, further processing is necessary to extract additional attributes such as travel mode (Zhang et al., 2011; Sadeghian et al., 2021). Detecting travel modes using GPS data has attracted considerable research interest, with various methods offering different advantages and limitations. Machine learning algorithms, particularly unsupervised and deep learning approaches, are increasingly utilized due to their ability to handle large datasets and achieve accurate clustering (Li et al., 2020; Markos &amp; Yu, 2020; Yu, 2021; Sadeghian et al., 2021). However, these methods often categorize only a limited number of modes and may not always integrate additional GIS layers, which can be achieved through rule-based methods (Sadeghian et al., 2021; Wu et al., 2016).</p>
<p>Rule-based methods, while potentially less accurate overall, offer the precision of distinguishing up to 12 transport modes by incorporating additional GIS layers (Sadeghian et al., 2021). These methods rely on prior understanding and manually defined rules, making them more time-consuming and less transferable but beneficial in contexts where detailed mode differentiation is necessary (Sadeghian et al., 2021; Nitsche et al., 2014). The choice between machine learning and rule-based methods ultimately depends on the study’s specific objectives and the required balance between accuracy, precision, and applicability.</p>
<p>Handheld mobile devices collecting GPS data facilitate straightforward collection of travel traces from various modes of transport, such as walking, cycling, and driving. These data can enhance existing road maps and support location-based services (Schroedl et al., 2004; Zhang et al., 2010). However, accurately identifying travel modes from GPS traces poses challenges due to similarities in travel characteristics across different modes and potential errors.</p>
<p>Given POSMO’s practical applications, our primary goal is to determine different travel modes as accurately as possible using GPS data and road maps. Therefore, we aim to implement a rule-based data science approach in R to identify travel modes using mobile GPS data. We will evaluate all travel modes present in our training data, including walking, biking, car, bus, and train, to address the following research question:</p>
<ul>
<li>To what extent can the mode of transportation be accurately determined using GPS data, in conjunction with road maps and public transport route maps?</li>
</ul>
<p>In conclusion, we would like to note that both members of the team contributed equally to the development of the code and the preparation of this report.</p>
</section>
<section id="material-and-methods" class="level2">
<h2 class="anchored" data-anchor-id="material-and-methods">Material and Methods</h2>
<section id="datasets-and-models" class="level3">
<h3 class="anchored" data-anchor-id="datasets-and-models">Datasets and Models</h3>
<section id="data-collection" class="level4">
<h4 class="anchored" data-anchor-id="data-collection">Data Collection</h4>
<p>To develop our travel mode detection method, we collected movement data from a team member using the POSMO app (Genossenschaft Posmo, 2024) over a span of 21 days (from April 5, 2024, to April 26, 2024). During this timeframe, 12’404 data points were recorded, with a sampling rate set 15 seconds. For the next steps in our method, we focused on the following attributes:</p>
<ul>
<li>Datetime: Timestamp of each recorded data point</li>
<li>Geometry: X- and Y-Coordinates in the CH1903+ LV95 coordinate system</li>
</ul>
</section>
<section id="supplementary-data" class="level4">
<h4 class="anchored" data-anchor-id="supplementary-data">Supplementary Data</h4>
<p>In addition to the primary data collected with the POSMO app, we incorporated the swissTLM3D dataset provided by swisstopo (2024). The feature classes and attributes extracted from this dataset include:</p>
<ul>
<li>TLM_STRASSE (OBJEKTART, geometry)</li>
<li>TLM_EISENBAHN (VERKEHRSMITTEL, geometry)</li>
<li>TLM_HALTESTELLE (OBJEKTART, geometry)</li>
</ul>
<p>A second POSMO-dataset provided by the same team member was used for validation. These data were collected over a period of 11days with a sampling rate of 15s, resulting in a total of 2567 fixes. It was eventually corrected and validated for travel mode in POSMO and the same attributes were further analyzed.</p>
</section>
<section id="data-preprocessing-conceptual-model" class="level4">
<h4 class="anchored" data-anchor-id="data-preprocessing-conceptual-model">Data preprocessing &amp; Conceptual Model</h4>
<p>For preprocessing, analysis, and visualization, we employed R (v. 4.2.3; R Core Team, 2020) and the ggplot2 package (v. 3.4.2; Wickham, 2016).</p>
<p>Following the approach outlined by Laube (2014), we conceptualized the movement space as a continuous, 2D, and entity-based model. All datasets were structured as vector data, representing the movement as a series of unconstrained, intermittent, and time-stamped fixes. The movement data were collected using a Lagrangian perspective, which involves tracking the individual movements over time.</p>
</section>
</section>
<section id="segmentation-and-filter" class="level3">
<h3 class="anchored" data-anchor-id="segmentation-and-filter">Segmentation and Filter</h3>
<p>According to Wu et al.&nbsp;(2016), to be able to assign transport modes to trajectories, we need to first divide our raw data into segments, that represent individual movements first (Figure 1). As an initial step, we calculated the distances for each point within a specified temporal window of v = 50 seconds (4 Ticks).</p>
<p>Then, Static points were identified by calculating for each position the average distance to the points before and after it. These distances were then summarized to an average value. Points whose stepMean was below the overall average were marked as static. Finally, these static points were filtered from the dataset. Next, the segments whose total stepMean value is not greater than the 25th percentile of all stepMean values were then removed (Figure 2).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Bilder//Segmentation.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Shows the segmentation of the trajectory without removing the static segments and the short segments</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Bilder//Statische%20Segmente%20Punkte%20entfernen.png" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Shows the segmentation of the trajectory with removal of the static segments and the short segments.</figcaption>
</figure>
</div>
</section>
<section id="calculating-movement-variables" class="level3">
<h3 class="anchored" data-anchor-id="calculating-movement-variables">Calculating Movement Variables</h3>
<p>To be able to detect our transport modes, we had to calculate some additional variables. Sadhegian et al.&nbsp;(2021) suggested that average speed, maximum speed and acceleration are the most common and important ones to do so. We computed speed according to Laube &amp; Purves (2011) using four fixes located inside a temporal window 60 seconds. The acceleration was calculated based on the same principle and defined as the change in speed over the change in time.</p>
<p>Then, the minimum, maximum, and average values for the two parameters were calculated for each segment (Figure 3). Additionally, each segment was assigned to the modified travel mode from POSMO. The different features of the two parameters were visualized based on their transportation mode for exploratory data analysis.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Bilder//transport_mode_boxplot.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3: Boxplot shows the distribution of speed and acceleration of the means of transport used. These values were used to determine the means of transport.</figcaption>
</figure>
</div>
<p>It is noticeable that most means of transportation show similar patterns or at least considerable similarities. Only the trajectories of trains differ significantly from the other modes of transportation in terms of speed and acceleration. Therefore, we decided to first embed the trajectories in their geographical context in order to improve the classification of the means of transportation.</p>
</section>
<section id="geographical-context" class="level3">
<h3 class="anchored" data-anchor-id="geographical-context">Geographical Context</h3>
<p>According to Gschwend (2015), movement patterns are usually quantified by geometric properties and the arrangement of fixed points, often ignoring the geographical environment that could provide valuable semantic insights. Therefore, incorporating external information can significantly improve the efficiency of algorithms (Sadeghian et al., 2021). As described in the chapter Datasets and Models, we used different feature classes from the swissTLM3D dataset and merged all roads and railroads into a background layer. We then performed a spatial join by assigning each fixed point of the POSMO data to the closest feature, as shown in Figure 4 for an example day. Finally, each segment was assigned the feature that corresponded to the most fixed points within that segment.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Bilder//USED_transport_Infrasturcutre_onde%20day.png" class="img-fluid figure-img"></p>
<figcaption>Figure 4: The map illustrates the routes taken by pedestrians, cyclists and public transport users during the day, with the latter divided into routes served by different modes of transport.</figcaption>
</figure>
</div>
<p>In addition, the swissTLM3D feature class TLM_HALTESTELLE, which includes stops for buses, trains and ships, was used to create a 75-meter buffer around each stop. A spatial join was created for fixes within these buffer zones. It was then recorded for each segment whether the first and last points were within a stop buffer in order to use this information for further analysis.</p>
</section>
<section id="transport-mode-detection" class="level3">
<h3 class="anchored" data-anchor-id="transport-mode-detection">Transport Mode Detection</h3>
<p>The next step was to use the geographical context information for a classification into the transport modes. In that way, the trajectories were classified as follows: trains (closest to train tracks), trams (closest to tram tracks), and buses (first and last stops within a bus or train stop buffer). This was done step by step, so that trajectories classified once were not able to be classified again. In order to assign the other trajectories, we used the visualization of the movement parameters (Figure 3) to estimate what thresholds should be applied. In that way, we decided to classify the mode of transportation as car if he maximum speed was greater than 20 km/h or the maximum acceleration was greater than 0.3 m/s² and if the average speed was over 2 km/h or the maximum speed was over 5 km/h, the mode of transport was classified as bike.</p>
</section>
<section id="validation" class="level3">
<h3 class="anchored" data-anchor-id="validation">Validation</h3>
<p>The next step was to compare the result of our transport mode detection with the POSMO classification and create a confusion matrix. However, since our method originally consists of this data, this cannot be counted as an actual validation. In order to properly test our method, a second data set from POSMO, which was recorded over a period of 11 days, was subjected to the same methodology as our training data set, except that we have manually checked the transportation modes specified by POSMO in this dataset and corrected them if necessary. The results of this second transport mode detection were then used to create another confusion matrix.</p>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>In the validation of the transportation modes in our training dataset, we achieved an accuracy of 35 % with our method (Figure 5). If we apply the same method to the validation dataset, the confusion matrix shows (Figure 6) a correct detection of 88.2%, which is significantly higher. Looking at Figure 5, it is clear that the biggest problem area in the training data is the recognition of the train (n= 20) as a means of transportation (25 % correct classification). However, in the evaluation of the validation data, train is the mode of transport that was best recognized (100% correct classification). Apart from cars (78.2%), the other modes of transport were also recognized very well.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Bilder//Train_confmatrix.png" class="img-fluid figure-img"></p>
<figcaption>Figure 5: The confusion matrix of the training data, which compares the “Predicted” means of transport calculated by our model with the “Actual” from Posmo.</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Bilder//Val_conf_matr.png" class="img-fluid figure-img"></p>
<figcaption>Figure 6: The confusion matrix of the validation data, which compares the “Predicted” means of transport calculated by our model with the “Actual” from Posmo.</figcaption>
</figure>
</div>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>The results of our study reveal several critical points about the detection of transportation modes from GPS data using our proposed rule-based method.</p>
<p>Our method exhibited poor detection accuracy in the training dataset, which we attribute primarily to errors in the initial POSMO classification. Upon examining the raw data, we observed several unrealistic trajectories and instances where single trajectories were divided into multiple short segments. The POSMO app sometimes generated unrealistic trajectories, significantly affecting our model’s performance. The segmentation errors, where long trajectories were broken into several short segments without clear reasons, further compounded these issues. These mistakes were not detected and manually corrected during the initial data collection phase, which led to inaccuracies in the transportation mode detection. Low detection accuracy were evident across all transportation modes. However, they were most pronounced for train trajectories due to the higher number of train trips recorded.</p>
<p>For the validation dataset, we manually reviewed and corrected the POSMO classifications daily to ensure accuracy. This process aimed to rectify the errors present in the training data, ensuring that the transportation modes identified by POSMO were accurate. Consequently, our method achieved higher detection accuracy with the validated data. As can be seen in figure 6, no walk trajectories were detected, likely because these segments were too short and were filtered out during data preprocessing. This highlights a limitation in our methodology, where shorter, potentially valid segments were lost during filtering.</p>
<p>Despite these issues, our method demonstrated good accuracy (88,2 %) compared to other studies (Sadeghian et al., 2021; Wu et al., 2016). This suggests that, when provided with accurate input data, our approach is robust and effective in detecting various transportation modes.</p>
<p>However, our study had several limitations. The relatively small number of data points used limits the generalizability of our findings. It would be intriguing to see how our method performs with larger datasets. Furthermore, our method heavily depends on the correct initial classification by the POSMO app. Errors in the app’s data significantly impacted our results, highlighting the importance of reliable initial data for accurate mode detection. Although our research question was only partially answered, the parameters and geographic context we used resulted in good accuracy in mode detection. However, the condition that raw data and validation foundations are correct and suitable for the procedure is crucial for the success of this approach.</p>
<p>In summary, while our rule-based method shows promise, particularly when supplemented with manual correction and validation, it underscores the necessity of accurate initial data and larger datasets for improved performance and reliability in transportation mode detection.</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<p>Dabiri, S., Lu, C.-T., Heaslip, K., &amp; Reddy, C. K. (2020). Semi-Supervised Deep Learning Approach for Transportation Mode Identification Using GPS Trajectory Data. IEEE Transactions on Knowledge and Data Engineering, 32(5), 1010–1023. https://doi.org/10.1109/TKDE.2019.2896985</p>
<p>Gadziński, J. (2018). Perspectives of the use of smartphones in travel behaviour studies: Findings from a literature review and a pilot study. Transportation Research Part C: Emerging Technologies, 88, 74–86. https://doi.org/10.1016/j.trc.2018.01.011</p>
<p>Gschwend, C. (2015). Relating movement to geographic context: effects of preprocessing, relation methods and scale (Doctoral dissertation, University of Zurich).</p>
<p>Laube, P. (2014). Computational Movement Analysis. Springer International Publishing. https://doi.org/10.1007/978-3-319-10268-9</p>
<p>Laube, P., &amp; Purves, R. S. (2011). How fast is a cow? Cross‐Scale Analysis of Movement Data. Transactions in GIS, 15(3), 401–418. https://doi.org/10.1111/j.1467-9671.2011.01256.x</p>
<p>Li, L., Zhang, J., Wang, Y., &amp; Ran, B. (2019). Missing Value Imputation for Trafﬁc-Related Time Series Data Based on a Multi-View Learning Method. IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, 20(8).</p>
<p>Li, L., Zhu, J., Zhang, H., Tan, H., Du, B., &amp; Ran, B. (2020). Coupled application of generative adversarial networks and conventional neural networks for travel mode detection using GPS data. Transportation Research Part A: Policy and Practice, 136, 282–292. https://doi.org/10.1016/j.tra.2020.04.005</p>
<p>Markos, C., &amp; Yu, J. J. Q. (2020). Unsupervised Deep Learning for GPS-Based Transportation Mode Identification. 2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC), 1–6. https://doi.org/10.1109/ITSC45102.2020.9294673</p>
<p>Nitsche, P., Widhalm, P., Breuss, S., Brändle, N., &amp; Maurer, P. (2014). Supporting large-scale travel surveys with smartphones – A practical approach. Transportation Research Part C: Emerging Technologies, 43, 212–221. https://doi.org/10.1016/j.trc.2013.11.005</p>
<p>RStudio Team (2020). RStudio: Integrated Development for R. RStudio, PBC, Boston, MA URL http://www.rstudio.com/.</p>
<p>Sadeghian, P. (o. J.). Review and evaluation of methods in transport mode detection based on GPS tracking data.</p>
<p>Schroedl, S., Wagstaff, K., Rogers, S., Langley, P., &amp; Wilson, C. (2004). Mining GPS Traces for Map Refinement. Data Mining and Knowledge Discovery, 9(1), 59–87. https://doi.org/10.1023/B:DAMI.0000026904.74892.89</p>
<p>Stopher, P. R., &amp; Greaves, S. P. (2007). Household travel surveys: Where are we going? Transportation Research Part A: Policy and Practice, 41(5), 367–381. https://doi.org/10.1016/j.tra.2006.09.005</p>
<p>Wickham H (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. ISBN 978-3-319-24277-4, https://ggplot2.tidyverse.org.</p>
<p>Wu, L., Yang, B., &amp; Jing, P. (2016). Travel Mode Detection Based on GPS Raw Data Collected by Smartphones: A Systematic Review of the Existing Methodologies. Information, 7(4), 67. https://doi.org/10.3390/info7040067</p>
<p>Yu, J. J. Q. (2021). Travel Mode Identification With GPS Trajectories Using Wavelet Transform and Deep Learning. IEEE Transactions on Intelligent Transportation Systems, 22(2), 1093–1103. https://doi.org/10.1109/TITS.2019.2962741</p>
<p>Zhang, L., Dalyot, S., Eggert, D., &amp; Sester, M. (2011). MULTI-STAGE APPROACH TO TRAVEL-MODE SEGMENTATION AND CLASSIFICATION OF GPS TRACES.</p>
<p>Zhang, L., Thiemann, F., &amp; Sester, M. (o. J.). Integration of GPS traces with road map.</p>
<section id="wordcount" class="level3">
<h3 class="anchored" data-anchor-id="wordcount">Wordcount</h3>
<!-- after installing the wordcountadding, remove the line "#| eval: false" -->
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"pacman"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">p_install_gh</span>(<span class="st">"benmarwick/wordcountaddin"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>wordcountaddin<span class="sc">::</span><span class="fu">word_count</span>(<span class="st">"index.qmd"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2665</code></pre>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>